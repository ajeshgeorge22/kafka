[2016-07-20 11:01:41,696] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,745] INFO Property broker.id is overridden to 0 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,745] INFO Property log.cleaner.enable is overridden to false (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,745] INFO Property log.dirs is overridden to /tmp/kafka-logs (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,746] INFO Property log.retention.check.interval.ms is overridden to 300000 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,746] INFO Property log.retention.hours is overridden to 168 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,746] INFO Property log.segment.bytes is overridden to 1073741824 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,746] INFO Property num.io.threads is overridden to 8 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,746] INFO Property num.network.threads is overridden to 3 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,746] INFO Property num.partitions is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property num.recovery.threads.per.data.dir is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property port is overridden to 9092 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property socket.receive.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property socket.request.max.bytes is overridden to 104857600 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property socket.send.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,747] INFO Property zookeeper.connection.timeout.ms is overridden to 6000 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:41,824] INFO [Kafka Server 0], starting (kafka.server.KafkaServer)
[2016-07-20 11:01:41,827] INFO [Kafka Server 0], Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-07-20 11:01:42,489] INFO Log directory '/tmp/kafka-logs' not found, creating it. (kafka.log.LogManager)
[2016-07-20 11:01:42,513] INFO Loading logs. (kafka.log.LogManager)
[2016-07-20 11:01:42,518] INFO Logs loading complete. (kafka.log.LogManager)
[2016-07-20 11:01:42,519] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2016-07-20 11:01:42,542] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2016-07-20 11:01:42,576] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2016-07-20 11:01:42,577] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)
[2016-07-20 11:01:42,680] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2016-07-20 11:01:42,733] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2016-07-20 11:01:43,043] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2016-07-20 11:01:43,066] INFO Registered broker 0 at path /brokers/ids/0 with address ajesh:9092. (kafka.utils.ZkUtils$)
[2016-07-20 11:01:43,075] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
[2016-07-20 11:01:43,368] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test,0],[hello,0],[sample,0],[helloworld,0] (kafka.server.ReplicaFetcherManager)
[2016-07-20 11:01:43,411] INFO Completed load of log test-0 with log end offset 0 (kafka.log.Log)
[2016-07-20 11:01:43,418] INFO Created log for partition [test,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-07-20 11:01:43,419] WARN Partition [test,0] on broker 0: No checkpointed highwatermark is found for partition [test,0] (kafka.cluster.Partition)
[2016-07-20 11:01:43,436] INFO Completed load of log hello-0 with log end offset 0 (kafka.log.Log)
[2016-07-20 11:01:43,438] INFO Created log for partition [hello,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-07-20 11:01:43,439] WARN Partition [hello,0] on broker 0: No checkpointed highwatermark is found for partition [hello,0] (kafka.cluster.Partition)
[2016-07-20 11:01:43,442] INFO Completed load of log sample-0 with log end offset 0 (kafka.log.Log)
[2016-07-20 11:01:43,444] INFO Created log for partition [sample,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-07-20 11:01:43,444] WARN Partition [sample,0] on broker 0: No checkpointed highwatermark is found for partition [sample,0] (kafka.cluster.Partition)
[2016-07-20 11:01:43,451] INFO Completed load of log helloworld-0 with log end offset 0 (kafka.log.Log)
[2016-07-20 11:01:43,454] INFO Created log for partition [helloworld,0] in /tmp/kafka-logs with properties {segment.index.bytes -> 10485760, file.delete.delay.ms -> 60000, segment.bytes -> 1073741824, flush.ms -> 9223372036854775807, delete.retention.ms -> 86400000, index.interval.bytes -> 4096, retention.bytes -> -1, min.insync.replicas -> 1, cleanup.policy -> delete, unclean.leader.election.enable -> true, segment.ms -> 604800000, max.message.bytes -> 1000012, flush.messages -> 9223372036854775807, min.cleanable.dirty.ratio -> 0.5, retention.ms -> 604800000, segment.jitter.ms -> 0}. (kafka.log.LogManager)
[2016-07-20 11:01:43,454] WARN Partition [helloworld,0] on broker 0: No checkpointed highwatermark is found for partition [helloworld,0] (kafka.cluster.Partition)
[2016-07-20 11:01:43,475] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test,0],[hello,0],[sample,0],[helloworld,0] (kafka.server.ReplicaFetcherManager)
[2016-07-20 11:01:47,966] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,991] INFO Property broker.id is overridden to 2 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,991] INFO Property log.cleaner.enable is overridden to false (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,991] INFO Property log.dirs is overridden to /tmp/kafka-logs (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property log.retention.check.interval.ms is overridden to 300000 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property log.retention.hours is overridden to 168 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property log.segment.bytes is overridden to 1073741824 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property num.io.threads is overridden to 8 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property num.network.threads is overridden to 3 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property num.partitions is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,992] INFO Property num.recovery.threads.per.data.dir is overridden to 1 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,993] INFO Property port is overridden to 9093 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,993] INFO Property socket.receive.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,993] INFO Property socket.request.max.bytes is overridden to 104857600 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,993] INFO Property socket.send.buffer.bytes is overridden to 102400 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,993] INFO Property zookeeper.connect is overridden to localhost:2181 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:47,993] INFO Property zookeeper.connection.timeout.ms is overridden to 6000 (kafka.utils.VerifiableProperties)
[2016-07-20 11:01:48,027] INFO [Kafka Server 2], starting (kafka.server.KafkaServer)
[2016-07-20 11:01:48,028] INFO [Kafka Server 2], Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2016-07-20 11:01:48,327] FATAL [Kafka Server 2], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:194)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:194)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:33)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:194)
	at scala.collection.mutable.WrappedArray.map(WrappedArray.scala:33)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:335)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:85)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:46)
	at kafka.Kafka.main(Kafka.scala)
[2016-07-20 11:01:48,331] INFO [Kafka Server 2], shutting down (kafka.server.KafkaServer)
[2016-07-20 11:01:48,340] INFO [Kafka Server 2], shut down completed (kafka.server.KafkaServer)
[2016-07-20 11:01:48,340] FATAL Fatal error during KafkaServerStartable startup. Prepare to shutdown (kafka.server.KafkaServerStartable)
kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:98)
	at kafka.log.LogManager$$anonfun$lockLogDirs$1.apply(LogManager.scala:95)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:194)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:194)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:34)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:33)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:194)
	at scala.collection.mutable.WrappedArray.map(WrappedArray.scala:33)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:95)
	at kafka.log.LogManager.<init>(LogManager.scala:57)
	at kafka.server.KafkaServer.createLogManager(KafkaServer.scala:335)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:85)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:29)
	at kafka.Kafka$.main(Kafka.scala:46)
	at kafka.Kafka.main(Kafka.scala)
[2016-07-20 11:01:48,346] INFO [Kafka Server 2], shutting down (kafka.server.KafkaServer)
[2016-07-20 11:02:18,621] INFO Closing socket connection to /127.0.0.1. (kafka.network.Processor)
